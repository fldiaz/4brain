{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JldD11sj01HP"
   },
   "source": [
    "# Today you are a MLE@Samsung Research and your goal is to perform segmentation of cystic regions from OCT images.\n",
    "## This work is based on the recent publication https://arxiv.org/abs/2008.02952\n",
    "## This model is adapted from the original codebase in https://github.com/sohiniroych/U-net_using_TF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDOV4Jc001HS"
   },
   "source": [
    "# Optical Coherence Tomography (OCT) images represent grayscale images representing the depth of retina. Cystic regions are gaps in the retina as shown below:\n",
    "<img src='https://drive.google.com/uc?id=1YRljOSUMEBLKBCSiU1TOAfwnoBcrV7LS' width=\"600\">\n",
    "\n",
    "\n",
    "## Your goal is to segment the cysts (dark gaps) in the images using the U-net model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzqk6qtk01HT"
   },
   "source": [
    "# Your Deliverables are as follows:\n",
    "### 1. Train a u-net model from scratch and test performance on test images for 2 OCT repos.\n",
    "### 2. Vary the loss function, kernel dilation, depthwise separability of the kernels, and report results.\n",
    "### 3. Report observations with and without Batch normalization and Dropout at test time.\n",
    "### 4. If you use Dropout at test time and generate 2-3 test predictions, what do you observe from these predictions? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvx3_dSP01HT"
   },
   "source": [
    "# Task 1: Construct U-net model from scratch for the 'cirrus_3' data set. Report performance on test set and save the model to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yeDAkRJue6N"
   },
   "source": [
    "### If using Colab, mount your Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1631772160324,
     "user": {
      "displayName": "Spencer Kent",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07841346171340846448"
     },
     "user_tz": 360
    },
    "id": "fV8HKsvDuOi1",
    "outputId": "c1a3bec1-f70f-4a4b-c2a9-0332dd62a86c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eAJCw3i-KCU"
   },
   "source": [
    "### If you're running locally, especially with RTX series GPUs, limiting GPU memory growth can be helpful. Otherwise ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiK7eWq_01HT"
   },
   "outputs": [],
   "source": [
    "#This code snippet helps if your computer has RTX 2070 GPU. If not then comment this cell.\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WdAv64z01HU"
   },
   "source": [
    "## Lets start by stepwise defining all libraries and functions needed to generate the model and pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V65jXPdK01HV"
   },
   "outputs": [],
   "source": [
    "#Step 1: Load libraries for the U-net Model\n",
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwMC3TB701HV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGHiRrJU01HW"
   },
   "outputs": [],
   "source": [
    "#Step 2: Define the U-net model\n",
    "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
    "    inputs = tf.keras.Input(shape=input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu',padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', dilation_rate=2,padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', dilation_rate=2, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "    \n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    \n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    \n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "   \n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel=keras.models.load_model(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxKjSs6f01HX"
   },
   "outputs": [],
   "source": [
    "# Change directory to wherever you've stored unet_helper_functions, for instance for my Colab:\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Live_session_notebooks/week_7/')  # change this for your system\n",
    "\n",
    "#All additional functions for data prep and evaluation are housed in unet_helper_finctions.py\n",
    "from unet_helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2liLJkV01HY"
   },
   "source": [
    "## All definitions are now done! Lets start using the functions now...\n",
    "## B. Call to image data generator, model initialization, followed by model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypgHIvpS01HY"
   },
   "outputs": [],
   "source": [
    "#Step 1: Call to image data generator in keras\n",
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=[0.7,1],\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "PATH='/content/drive/MyDrive/Datasets/week_7/Data/cirrus_3/'  # give the path to where you've stored and decompressed Data.zip, the cirrus_3 subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vx85_DgM01HY"
   },
   "outputs": [],
   "source": [
    "data_gen = trainGenerator(10,PATH+'train/','Image','GT',data_gen_args)\n",
    "\n",
    "############### \n",
    "# If you want to view the augmented training images you can run these three lines instead of the one above\n",
    "###############\n",
    "# if not os.path.exists(PATH +'train/aug'):\n",
    "#     os.makedirs(PATH+'train/aug')\n",
    "# data_gen = trainGenerator(10,PATH+'train/','Image','GT',data_gen_args, save_to_dir = PATH+'train/aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 427,
     "status": "ok",
     "timestamp": 1631772165633,
     "user": {
      "displayName": "Spencer Kent",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07841346171340846448"
     },
     "user_tz": 360
    },
    "id": "jSSWo3FM01HY",
    "outputId": "cf8f461a-3231-423b-b529-eda961648a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256, 256, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 128 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 147584      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  590080      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 512)  2048        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  2359808     batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 512)  2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 1024) 4096        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 9438208     batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 1024) 4096        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 1024) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 32, 32, 1024) 0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 1024) 0           dropout[0][0]                    \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 512)  0           batch_normalization_5[0][0]      \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 256 0           batch_normalization_3[0][0]      \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 147584      conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 128 0           batch_normalization_1[0][0]      \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 2)  1154        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 1)  3           conv2d_22[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,047,557\n",
      "Trainable params: 31,039,621\n",
      "Non-trainable params: 7,936\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Initialize the model. We're going to train it from scratch!\n",
    "model = unet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEw7aTip01HZ"
   },
   "outputs": [],
   "source": [
    "##### Comment this cell out if you have any issues with tensorboard\n",
    "\n",
    "#Step 3: Initialize Tensorboard to monitor changes in Model Loss \n",
    "import datetime\n",
    "%load_ext tensorboard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ms48Ap9clp99"
   },
   "outputs": [],
   "source": [
    "# if you used tensorboard callbacks, try launching tensorboard to view the logs:\n",
    "# If developing locally: `tensorboard --logdir <THIS_DIRECTORY>/logs\n",
    "# If developing on Colab: `%tensorboard --logdir logs`\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BokWkOe01Ha"
   },
   "outputs": [],
   "source": [
    "#Step 4: Fit the u-net model\n",
    "\n",
    "# saves the best version of the model as `unet_cirrus3_V1.hdf5`\n",
    "model.fit(data_gen,steps_per_epoch=15,epochs=50,verbose=1,callbacks=[model_checkpoint_callback, tensorboard_callback])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MThVArs01Ha"
   },
   "source": [
    "## C. Run the trained model on test images and save the outputs, and evaluate pixel-level segmentation performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3J6g-xdz01Ha",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1: create a directory to store predicted segmentations\n",
    "if not os.path.exists(PATH+'test/pred_V1'):\n",
    "    os.makedirs(PATH+'test/pred_V1')\n",
    "\n",
    "#Step 2: Run model on test images and save the images\n",
    "#number of test images\n",
    "n_i=len(os.listdir(PATH+'test/Image/'))\n",
    "#Call test generator\n",
    "test_gen = testGenerator(PATH+'test/Image/')\n",
    "#Return model outcome for each test image\n",
    "results = model.predict_generator(test_gen,n_i,verbose=1)\n",
    "#If dropout is activated for test data, then calling this function multiple times will generate difefrent outputs!\n",
    "saveResult(PATH+'test/Image/', PATH+'test/pred_V1/',results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHf34X8m01Ha"
   },
   "outputs": [],
   "source": [
    "#Step 2: Evaluate the predicted outcome\n",
    "gt_path=PATH+'test/GT/'\n",
    "evalResult(gt_path,results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1E0yBjpc01Hb"
   },
   "source": [
    "# Task 2: Make some modifications to the model (kernels and loss function)\n",
    "\n",
    "* First create a version of the model `unet_mod` which uses dilated kernels (first try a dilation rate of 2 then you can experiment with other values). Train this model with the dice coefficient loss, while tracking the dice coefficient metric.\n",
    "\n",
    "Save the best version of this model (using the checkpoint callback as we did above) as `unet_cirrus3_V2.hdf5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TNLnPrl01HW"
   },
   "outputs": [],
   "source": [
    "#Define Additional loss functions for this task\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = keras.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = keras.sum(y_true, axis=[1,2,3]) + keras.sum(y_pred, axis=[1,2,3])\n",
    "    return keras.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dk8d3Vmy01Hb"
   },
   "outputs": [],
   "source": [
    "#Modify U-net Definition\n",
    "def unet_mod(pretrained_weights = None,input_size = (256,256,1)):\n",
    "    ### PUT YOUR MODIFIED VERSION OF UNET HERE ####\n",
    "    ###############################################\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel=keras.models.load_model(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IcXZCisY01Hb"
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model_mod=unet_mod()\n",
    "## YOUR CODE TO CHECKPOINT AND FIT THE MODEL HERE ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lwzd5lN801Hc"
   },
   "outputs": [],
   "source": [
    "def saveResult_raw(img_path,save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    files=os.listdir(img_path)\n",
    "    \n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path, files[i]+'_predict.png'),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYDafmN701Hc"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(PATH+'test/pred_V2'):\n",
    "    os.makedirs(PATH+'test/pred_V2')\n",
    "\n",
    "n_i=len(os.listdir(PATH + 'test/Image/'))\n",
    "test_gen = testGenerator(PATH+'test/Image/')\n",
    "results_mod = model_mod.predict_generator(test_gen,n_i,verbose=1)\n",
    "saveResult_raw(PATH+'test/Image/', PATH+'test/pred_V2/',results_mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xV4Fao301Hc"
   },
   "outputs": [],
   "source": [
    "gt_path=PATH+'test/GT/'\n",
    "evalResult(gt_path,results_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwljy6WdJWi8"
   },
   "source": [
    "* Now try making some of the convolution layers DepthwiseConv2D instead of Conv2D. Keep the dice coefficient as the metric and loss. Save a checkpoint of this nodel as `unet_cirrus3_v3.hdf5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDl7NtJT01Hc"
   },
   "outputs": [],
   "source": [
    "def unet_depth(pretrained_weights = None,input_size = (256,256,1)):\n",
    "    ### PUT YOUR MODIFIED VERSION OF UNET HERE ####\n",
    "    ###############################################\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel=tf.keras.models.load_model(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KbW5mBCr01Hd"
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model_depth=unet_depth()\n",
    "## YOUR CODE TO CHECKPOINT AND FIT THE MODEL HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AwqZn0WM01Hd"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(PATH+'test/pred_V3'):\n",
    "    os.makedirs(PATH+'test/pred_V3')\n",
    "\n",
    "n_i=len(os.listdir(PATH+'test/Image/'))\n",
    "test_gen = testGenerator(PATH+'test/Image/')\n",
    "results_depth = model_depth.predict_generator(test_gen,n_i,verbose=1)\n",
    "saveResult_raw(PATH+'test/Image/',PATH+'test/pred_V3/',results_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIT1AYa901Hd"
   },
   "outputs": [],
   "source": [
    "gt_path=PATH+'test/GT/'\n",
    "evalResult(gt_path,results_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2v576_P101Hd"
   },
   "source": [
    "## Select the best network parameters for semantic segmentation here and save the best model as unet_cirrus3.hdf5! Enter metrics for the three versions of your model into the table below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyRhX7nH01Hc"
   },
   "source": [
    "|U-net Parameters  (cirrus_3)          | Precision|Recall|IoU   |acc   |F1    | Size |\n",
    "|------|-------|---------|-------------|----------|--------------|--------|\n",
    "|binary cross entropy loss    |    **   |  **   |  **  | ** | **  | ** (MB) |\n",
    "|dilated kernels, dice coef|     **  | ** | ** | ** | ** | ** (MB) |\n",
    "|depthwise separable kernels, dice coef|   **    |  **  |  **  | ** | ** | ** (MB) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGI8K-PO01Hd"
   },
   "source": [
    "# Task 3: Perform transfer learning with each of the `unet_cirrus3_Vx.hdf5` as the base weights and retrain (fine-tune) on the 'nidek1' data set . Report the same table as above for the 'nidek1' test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gabnl1xk01He"
   },
   "source": [
    "# Task 4: Report test performance on Cirrus3 and Nidek1 for the following:\n",
    "## A. Remove the BatchNormalization commands.\n",
    "## B. Activate dropout on test data (enable training=True) and create 2 cyst masks for each test image. Comment on the overlap between the cyst masks per image. What do you learn here?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "week7_V1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
